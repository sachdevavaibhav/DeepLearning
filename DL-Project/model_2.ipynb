{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558132a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26eb2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Inception-ResNet-V2 model\n",
    "base_model = tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(250,250,3))\n",
    "\n",
    "# Freeze the pre-trained weights\n",
    "base_model.trainable = False\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (250, 250, 3)\n",
    "\n",
    "# Define the input layer\n",
    "inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "# Pass the input layer through the pre-trained model\n",
    "features = base_model(inputs)\n",
    "\n",
    "# Add a dense layer for multi-class classification\n",
    "# outputs = tf.keras.layers.Dense(units=8, activation='sigmoid')(features)\n",
    "\n",
    "outputs = tf.keras.layers.Flatten()(features)\n",
    "outputs = tf.keras.layers.Dense(units=8, activation='sigmoid')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a82410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "f1_score = tfa.metrics.F1Score(num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465e6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "# Compile the model\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "               loss='binary_crossentropy',\n",
    "              metrics=['accuracy', precision , recall, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb595890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 250, 250, 3)]     0         \n",
      "                                                                 \n",
      " inception_resnet_v2 (Functi  (None, 6, 6, 1536)       54336736  \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 55296)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 442376    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,779,112\n",
      "Trainable params: 442,376\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0519635",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/User/DeepLearning/DL-Project/updated_left_eye.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15940\\1895601520.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load both left and right eye dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/User/DeepLearning/DL-Project'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mleft_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{base_path}/updated_left_eye.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mright_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{base_path}/updated_right_eye.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     ) as handle:\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/User/DeepLearning/DL-Project/updated_left_eye.xlsx'"
     ]
    }
   ],
   "source": [
    "# Load the image data and one-hot encoded multi-label data\n",
    "# Load the data from the excel sheet into a pandas dataframe\n",
    "# Load both left and right eye dataset\n",
    "base_path = 'C:/Users/User/DeepLearning/DL-Project'\n",
    "left_df = pd.read_excel(f'{base_path}/updated_left_eye.xlsx')\n",
    "right_df = pd.read_excel(f'{base_path}/updated_right_eye.xlsx')\n",
    "\n",
    "#concating both dataframes\n",
    "df = pd.concat([left_df, right_df], axis=0)\n",
    "\n",
    "\n",
    "# Split the data into two arrays, one for the image paths and one for the labels\n",
    "images_base_path = 'E:/odir-dataset/ODIR-5K/ODIR-5K/cropped_training_images/'\n",
    "image_paths = images_base_path + df[\"Fundus\"].values\n",
    "labels = df.iloc[:, 3:].values\n",
    "\n",
    "# Convert the lists to tensors\n",
    "image_paths = tf.constant(image_paths)\n",
    "labels = tf.constant(labels)\n",
    "\n",
    "# Create a dataset from the image paths and labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fcda94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image data and one-hot encoded multi-label data\n",
    "# Load the data from the excel sheet into a pandas dataframe\n",
    "# Load both left and right eye dataset\n",
    "base_path = 'C:/Users/manik/DL-Project/DeepLearning/DL-Project'\n",
    "left_df = pd.read_excel(f'{base_path}/updated_left_eye.xlsx')\n",
    "right_df = pd.read_excel(f'{base_path}/updated_right_eye.xlsx')\n",
    "\n",
    "#concating both dataframes\n",
    "df = pd.concat([left_df, right_df], axis=0)\n",
    "\n",
    "\n",
    "# Split the data into two arrays, one for the image paths and one for the labels\n",
    "images_base_path = 'D:/cropped_training_images/'\n",
    "image_paths = images_base_path + df[\"Fundus\"].values\n",
    "labels = df.iloc[:, 3:].values\n",
    "\n",
    "# Convert the lists to tensors\n",
    "image_paths = tf.constant(image_paths)\n",
    "labels = tf.constant(labels)\n",
    "\n",
    "# Create a dataset from the image paths and labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628307f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images and preprocess them\n",
    "def load_and_preprocess_image(file_path, label):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [250, 250])\n",
    "    image = tf.keras.applications.inception_resnet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Apply the load_and_preprocess_image function to the dataset\n",
    "dataset = dataset.map(load_and_preprocess_image)\n",
    "\n",
    "# Shuffle the data and batch it\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(buffer_size=len(image_paths)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce1df36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 250, 250, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 8), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e72b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, train_split, test_split, val_split):\n",
    "    # Calculate the size of each split\n",
    "    dataset_size = dataset.reduce(tf.constant(0, dtype=tf.int64), lambda acc, _: acc + 1).numpy()\n",
    "    train_size = int(dataset_size * train_split)\n",
    "    val_size = int(dataset_size * val_split)\n",
    "    test_size = int(dataset_size * test_split)\n",
    "\n",
    "    # Shuffle the elements of the dataset randomly\n",
    "    dataset = dataset.shuffle(buffer_size=dataset_size, seed=42)\n",
    "\n",
    "    # Split the dataset into train, validation, and test sets\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    remaining_dataset = dataset.skip(train_size)\n",
    "    val_dataset = remaining_dataset.take(val_size)\n",
    "    test_dataset = remaining_dataset.skip(val_size)\n",
    "    return train_dataset, test_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aecb7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\manik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_dataset, test_dataset, val_dataset = split_data(dataset, train_split=0.7, test_split=0.15, val_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3d6410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "152/152 [==============================] - 1026s 6s/step - loss: 7.8826 - accuracy: 0.4421 - precision: 0.1379 - recall: 0.9877 - f1_score: 0.2124 - val_loss: 4.9353 - val_accuracy: 0.4407 - val_precision: 0.1341 - val_recall: 1.0000 - val_f1_score: 0.2136\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 1003s 6s/step - loss: 4.5284 - accuracy: 0.4485 - precision: 0.1340 - recall: 1.0000 - f1_score: 0.2117 - val_loss: 3.2648 - val_accuracy: 0.4301 - val_precision: 0.1344 - val_recall: 1.0000 - val_f1_score: 0.2145\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 907s 6s/step - loss: 4.1962 - accuracy: 0.4484 - precision: 0.1341 - recall: 1.0000 - f1_score: 0.2124 - val_loss: 5.8221 - val_accuracy: 0.4651 - val_precision: 0.1324 - val_recall: 1.0000 - val_f1_score: 0.2091\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 1038s 6s/step - loss: 4.7766 - accuracy: 0.4393 - precision: 0.1339 - recall: 1.0000 - f1_score: 0.2127 - val_loss: 5.5564 - val_accuracy: 0.4476 - val_precision: 0.1333 - val_recall: 1.0000 - val_f1_score: 0.2106\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 1136s 7s/step - loss: 3.5150 - accuracy: 0.4370 - precision: 0.1341 - recall: 1.0000 - f1_score: 0.2134 - val_loss: 2.3887 - val_accuracy: 0.4403 - val_precision: 0.1342 - val_recall: 1.0000 - val_f1_score: 0.2134\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 1224s 7s/step - loss: 3.6396 - accuracy: 0.4382 - precision: 0.1341 - recall: 1.0000 - f1_score: 0.2129 - val_loss: 2.2765 - val_accuracy: 0.4550 - val_precision: 0.1345 - val_recall: 1.0000 - val_f1_score: 0.2124\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 1079s 6s/step - loss: 3.1384 - accuracy: 0.4393 - precision: 0.1340 - recall: 1.0000 - f1_score: 0.2128 - val_loss: 2.9217 - val_accuracy: 0.4833 - val_precision: 0.1334 - val_recall: 1.0000 - val_f1_score: 0.2089\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 1285s 8s/step - loss: 2.9918 - accuracy: 0.4436 - precision: 0.1338 - recall: 1.0000 - f1_score: 0.2121 - val_loss: 3.5385 - val_accuracy: 0.4476 - val_precision: 0.1350 - val_recall: 1.0000 - val_f1_score: 0.2140\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 1275s 7s/step - loss: 2.4251 - accuracy: 0.4452 - precision: 0.1340 - recall: 1.0000 - f1_score: 0.2125 - val_loss: 1.8144 - val_accuracy: 0.4384 - val_precision: 0.1334 - val_recall: 1.0000 - val_f1_score: 0.2116\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 1206s 7s/step - loss: 3.0075 - accuracy: 0.4439 - precision: 0.1345 - recall: 1.0000 - f1_score: 0.2130 - val_loss: 2.6109 - val_accuracy: 0.4246 - val_precision: 0.1353 - val_recall: 1.0000 - val_f1_score: 0.2161\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history=model.fit(train_dataset, epochs=10, batch_size=batch_size, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3058bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/User/DeepLearning/DL-Project/models/model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e046e0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "152/152 [==============================] - 831s 5s/step - loss: 0.3348 - accuracy: 0.4598 - precision: 0.4875 - recall: 0.3199 - f1_score: 0.3167 - val_loss: 0.2715 - val_accuracy: 0.5389 - val_precision: 0.5649 - val_recall: 0.4335 - val_f1_score: 0.4037\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 668s 4s/step - loss: 0.2697 - accuracy: 0.5340 - precision: 0.5953 - recall: 0.4032 - f1_score: 0.4202 - val_loss: 0.2306 - val_accuracy: 0.6131 - val_precision: 0.6887 - val_recall: 0.4418 - val_f1_score: 0.5232\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 815s 5s/step - loss: 0.2491 - accuracy: 0.5765 - precision: 0.6394 - recall: 0.4291 - f1_score: 0.4903 - val_loss: 0.2276 - val_accuracy: 0.5744 - val_precision: 0.7027 - val_recall: 0.4487 - val_f1_score: 0.4446\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 840s 5s/step - loss: 0.2322 - accuracy: 0.6063 - precision: 0.6667 - recall: 0.4805 - f1_score: 0.5387 - val_loss: 0.2089 - val_accuracy: 0.6360 - val_precision: 0.8080 - val_recall: 0.4126 - val_f1_score: 0.5642\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 674s 4s/step - loss: 0.2102 - accuracy: 0.6367 - precision: 0.6999 - recall: 0.5183 - f1_score: 0.6001 - val_loss: 0.1934 - val_accuracy: 0.6801 - val_precision: 0.7187 - val_recall: 0.6147 - val_f1_score: 0.5942\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 694s 4s/step - loss: 0.1995 - accuracy: 0.6602 - precision: 0.7332 - recall: 0.5432 - f1_score: 0.6371 - val_loss: 0.1852 - val_accuracy: 0.7114 - val_precision: 0.7588 - val_recall: 0.6615 - val_f1_score: 0.6806\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 701s 4s/step - loss: 0.1934 - accuracy: 0.6783 - precision: 0.7459 - recall: 0.5649 - f1_score: 0.6528 - val_loss: 0.1736 - val_accuracy: 0.7259 - val_precision: 0.8592 - val_recall: 0.5200 - val_f1_score: 0.6839\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 692s 4s/step - loss: 0.1733 - accuracy: 0.7181 - precision: 0.7829 - recall: 0.6038 - f1_score: 0.7163 - val_loss: 0.1624 - val_accuracy: 0.7482 - val_precision: 0.8699 - val_recall: 0.5293 - val_f1_score: 0.7523\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 710s 4s/step - loss: 0.1662 - accuracy: 0.7278 - precision: 0.7934 - recall: 0.6189 - f1_score: 0.7300 - val_loss: 0.1797 - val_accuracy: 0.6829 - val_precision: 0.7078 - val_recall: 0.5946 - val_f1_score: 0.7062\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 692s 4s/step - loss: 0.1677 - accuracy: 0.7192 - precision: 0.7861 - recall: 0.6274 - f1_score: 0.7348 - val_loss: 0.1683 - val_accuracy: 0.6590 - val_precision: 0.7063 - val_recall: 0.6464 - val_f1_score: 0.6469\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history=model.fit(train_dataset, epochs=10, batch_size=batch_size, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9567a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/manik/DL-Project/DeepLearning/DL-Project/models/model_2_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a78f9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('C:/Users/manik/DL-Project/DeepLearning/DL-Project/models/model_2_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e58e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "               loss='binary_crossentropy',\n",
    "              metrics=['accuracy', precision , recall, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c56605bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 250, 250, 3)]     0         \n",
      "                                                                 \n",
      " inception_resnet_v2 (Functi  (None, 6, 6, 1536)       54336736  \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 55296)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 442376    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,779,112\n",
      "Trainable params: 442,376\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "596466df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "152/152 [==============================] - 686s 4s/step - loss: 0.1343 - accuracy: 0.8082 - precision: 0.8376 - recall: 0.6979 - f1_score: 0.7869 - val_loss: 0.1332 - val_accuracy: 0.8051 - val_precision: 0.8559 - val_recall: 0.7422 - val_f1_score: 0.8145\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 731s 4s/step - loss: 0.1353 - accuracy: 0.8116 - precision: 0.8702 - recall: 0.7058 - f1_score: 0.8193 - val_loss: 0.1328 - val_accuracy: 0.8226 - val_precision: 0.8813 - val_recall: 0.7504 - val_f1_score: 0.8258\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 1141s 7s/step - loss: 0.1318 - accuracy: 0.8172 - precision: 0.8832 - recall: 0.7241 - f1_score: 0.8291 - val_loss: 0.1290 - val_accuracy: 0.8061 - val_precision: 0.8707 - val_recall: 0.7453 - val_f1_score: 0.8495\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 1181s 7s/step - loss: 0.1331 - accuracy: 0.8138 - precision: 0.8850 - recall: 0.7215 - f1_score: 0.8304 - val_loss: 0.1302 - val_accuracy: 0.8287 - val_precision: 0.9039 - val_recall: 0.7089 - val_f1_score: 0.8488\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 1168s 7s/step - loss: 0.1305 - accuracy: 0.8238 - precision: 0.8886 - recall: 0.7250 - f1_score: 0.8381 - val_loss: 0.1326 - val_accuracy: 0.7895 - val_precision: 0.8601 - val_recall: 0.7094 - val_f1_score: 0.8526\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 1026s 6s/step - loss: 0.1307 - accuracy: 0.8161 - precision: 0.8867 - recall: 0.7279 - f1_score: 0.8337 - val_loss: 0.1272 - val_accuracy: 0.8309 - val_precision: 0.9024 - val_recall: 0.6969 - val_f1_score: 0.8538\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 680s 4s/step - loss: 0.1282 - accuracy: 0.8239 - precision: 0.8944 - recall: 0.7324 - f1_score: 0.8379 - val_loss: 0.1300 - val_accuracy: 0.8125 - val_precision: 0.8954 - val_recall: 0.7112 - val_f1_score: 0.8264\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 689s 4s/step - loss: 0.1269 - accuracy: 0.8267 - precision: 0.8924 - recall: 0.7356 - f1_score: 0.8445 - val_loss: 0.1259 - val_accuracy: 0.8585 - val_precision: 0.9070 - val_recall: 0.7348 - val_f1_score: 0.8878\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 746s 4s/step - loss: 0.1258 - accuracy: 0.8305 - precision: 0.8956 - recall: 0.7414 - f1_score: 0.8476 - val_loss: 0.1274 - val_accuracy: 0.7978 - val_precision: 0.8740 - val_recall: 0.7297 - val_f1_score: 0.8413\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 721s 4s/step - loss: 0.1258 - accuracy: 0.8265 - precision: 0.8990 - recall: 0.7421 - f1_score: 0.8529 - val_loss: 0.1259 - val_accuracy: 0.8361 - val_precision: 0.9096 - val_recall: 0.7168 - val_f1_score: 0.8430\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history=model.fit(train_dataset, epochs=10, batch_size=batch_size, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1bf0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/manik/DL-Project/DeepLearning/DL-Project/models/model_2_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0026c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
